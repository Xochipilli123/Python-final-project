{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InitialPlantPath.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Xochipilli123/Python-final-project/blob/master/InitialPlantPath.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QgXv-Eocy42",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Requirements needed for the project\n",
        "import numpy as np\n",
        "import pickle\n",
        "import cv2\n",
        "from os import listdir\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81bkp4PAc82_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Information needed for Keras\n",
        "EPOCHS = 25\n",
        "INIT_LR = 1e-3\n",
        "BS = 32\n",
        "default_image_size = tuple((256, 256))\n",
        "image_size = 0\n",
        "directory_root = 'PlantVillage-Dataset/raw'\n",
        "width=256\n",
        "height=256\n",
        "depth=3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AzQtteDdAOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#converts images from plantVillage to arrays\n",
        "def convert_image_to_array(image_dir):\n",
        "    try:\n",
        "        image = cv2.imread(image_dir)\n",
        "        if image is not None :\n",
        "            image = cv2.resize(image, default_image_size)   \n",
        "            return img_to_array(image)\n",
        "        else :\n",
        "            return np.array([])\n",
        "    except Exception as e:\n",
        "        print(f\"Error : {e}\")\n",
        "        return None\n",
        " \"\"\"Arrays can be used to train a model, but (as far as I understand) images cannot, so cell converts images to arrays\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNpvTb1ogjFF",
        "colab_type": "code",
        "outputId": "f0b62630-150b-466f-c384-3a83cba73c21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        }
      },
      "source": [
        "#Get images from PlantVillage dataset\n",
        "image_list, label_list = [], []\n",
        "try:\n",
        "    print(\"[INFO] Loading images ...\")\n",
        "    root_dir = listdir(directory_root)\n",
        "    for directory in root_dir :\n",
        "        # remove .DS_Store from list\n",
        "        if directory == \".DS_Store\" :\n",
        "            root_dir.remove(directory)\n",
        "\n",
        "    for plant_folder in root_dir :\n",
        "        plant_disease_folder_list = listdir(f\"{directory_root}/{plant_folder}\")\n",
        "        \n",
        "        for disease_folder in plant_disease_folder_list :\n",
        "            # remove .DS_Store from list\n",
        "            if disease_folder == \".DS_Store\" :\n",
        "                plant_disease_folder_list.remove(disease_folder)\n",
        "\n",
        "        for plant_disease_folder in plant_disease_folder_list:\n",
        "            print(f\"[INFO] Processing {plant_disease_folder} ...\")\n",
        "            plant_disease_image_list = listdir(f\"{directory_root}/{plant_folder}/{plant_disease_folder}/\")\n",
        "                \n",
        "            for single_plant_disease_image in plant_disease_image_list :\n",
        "                if single_plant_disease_image == \".DS_Store\" :\n",
        "                    plant_disease_image_list.remove(single_plant_disease_image)\n",
        "\n",
        "            for image in plant_disease_image_list[:500]:\n",
        "                image_directory = f\"{directory_root}/{plant_folder}/{plant_disease_folder}/{image}\"\n",
        "                if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True:\n",
        "                    image_list.append(convert_image_to_array(image_directory))\n",
        "                    label_list.append(plant_disease_folder)\n",
        "    print(\"[INFO] Image loading completed\")  \n",
        "except Exception as e:\n",
        "    print(f\"Error : {e}\")\n",
        "    \n",
        "    \"\"\"Grabs images from root directory, which is the PlantVillage database. Only grabs .jpeg and the first 500 in image list\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Loading images ...\n",
            "[INFO] Processing Peach___healthy ...\n",
            "[INFO] Processing Soybean___healthy ...\n",
            "[INFO] Processing Potato___healthy ...\n",
            "[INFO] Processing Raspberry___healthy ...\n",
            "[INFO] Processing Apple___Apple_scab ...\n",
            "[INFO] Processing Tomato___Bacterial_spot ...\n",
            "[INFO] Processing Strawberry___healthy ...\n",
            "[INFO] Processing Corn_(maize)___healthy ...\n",
            "[INFO] Processing Tomato___Tomato_mosaic_virus ...\n",
            "[INFO] Processing Tomato___Early_blight ...\n",
            "[INFO] Processing Cherry_(including_sour)___Powdery_mildew ...\n",
            "[INFO] Processing Strawberry___Leaf_scorch ...\n",
            "[INFO] Processing Pepper,_bell___Bacterial_spot ...\n",
            "[INFO] Processing Tomato___healthy ...\n",
            "[INFO] Processing Squash___Powdery_mildew ...\n",
            "[INFO] Processing Tomato___Late_blight ...\n",
            "[INFO] Processing Grape___healthy ...\n",
            "[INFO] Processing Peach___Bacterial_spot ...\n",
            "[INFO] Processing Potato___Late_blight ...\n",
            "[INFO] Processing Grape___Black_rot ...\n",
            "[INFO] Processing Apple___Black_rot ...\n",
            "[INFO] Processing Grape___Leaf_blight_(Isariopsis_Leaf_Spot) ...\n",
            "[INFO] Processing Pepper,_bell___healthy ...\n",
            "[INFO] Processing Apple___Cedar_apple_rust ...\n",
            "[INFO] Processing Tomato___Target_Spot ...\n",
            "[INFO] Processing Blueberry___healthy ...\n",
            "[INFO] Processing Tomato___Spider_mites Two-spotted_spider_mite ...\n",
            "[INFO] Processing Tomato___Septoria_leaf_spot ...\n",
            "[INFO] Processing Corn_(maize)___Northern_Leaf_Blight ...\n",
            "[INFO] Processing Corn_(maize)___Common_rust_ ...\n",
            "[INFO] Processing Grape___Esca_(Black_Measles) ...\n",
            "[INFO] Processing Apple___healthy ...\n",
            "[INFO] Processing Orange___Haunglongbing_(Citrus_greening) ...\n",
            "[INFO] Processing Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzQJ03Bz4mtZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#converts labels to binary\n",
        "label_binarizer = LabelBinarizer()\n",
        "\n",
        "\"\"\"At learning time, this simply consists in learning one regressor or binary classifier per class. In doing so, one needs to convert multi-class labels to binary labels (belong or does not belong to the class). LabelBinarizer makes this process easy with the transform method.\n",
        "\n",
        "At prediction time, one assigns the class for which the corresponding model gave the greatest confidence. LabelBinarizer makes this easy with the inverse_transform method.- From Sklearn\"\"\"\n",
        "image_labels = label_binarizer.fit_transform(label_list)\n",
        "pickle.dump(label_binarizer,open('label_transform.pkl', 'wb'))\n",
        "n_classes = len(label_binarizer.classes_)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkCg_K8p4tAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(label_binarizer.classes_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMh-FsT84zc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#used to scale down RGB values\n",
        "np_image_list = np.array(image_list, dtype=np.float16) / 225.0\n",
        "\"\"\"Used to scale down RGB values. 225 is highest value\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VaVy94344Ie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"[INFO] Spliting data to train, test\")\n",
        "x_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.10, random_state = 50) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JZICQmM4_8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Modifies and copies sample images to use in training\n",
        "aug = ImageDataGenerator(\n",
        "    rotation_range=25, width_shift_range=0.1,\n",
        "    height_shift_range=0.1, shear_range=0.2, \n",
        "    zoom_range=0.2,horizontal_flip=True, \n",
        "    fill_mode=\"nearest\")\n",
        "    \"\"\"While used in one of the disease detecting scripts I found, I'm not sure it is totally needed in mine, as I have increased the sample size of mine. Nonetheless, taking it out dramatically lowers model accuracy\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pEJzta05H-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#formation of model\n",
        "model = Sequential()\n",
        "inputShape = (height, width, depth)\n",
        "chanDim = -1\n",
        "if K.image_data_format() == \"channels_first\":\n",
        "    inputShape = (depth, height, width)\n",
        "    chanDim = 1\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\"\"\"reduces overfitting in neural networks by preventing complex co-adaptations on training data\"\"\"\n",
        "model.add(Dense(n_classes))\n",
        "model.add(Activation(\"softmax\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3uDxAfT5Ko1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eKVDoZI5R3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Uses first-order gradient-based optimization of stochastic objective functions (Adam) to improve training\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "# distribution\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
        "# train the network\n",
        "print(\"[INFO] training network...\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYaKhQdo5SmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(\n",
        "    aug.flow(x_train, y_train, batch_size=BS),\n",
        "    validation_data=(x_test, y_test),\n",
        "    steps_per_epoch=len(x_train) // BS,\n",
        "    epochs=EPOCHS, verbose=1\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Qa73fRo5XER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Train and  plot validation accuracy, loss\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
        "plt.title('Training and Validation accurarcy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYMyX2UQ5b9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"[INFO] Calculating model accuracy\")\n",
        "scores = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {scores[1]*100}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjEDi06M5jcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "print(\"[INFO] Saving model...\")\n",
        "pickle.dump(model,open('plantpath.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}